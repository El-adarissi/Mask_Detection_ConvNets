{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Code Start Here**"
      ],
      "metadata": {
        "id": "TS9MHr6kxktw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Necessary Dependencies**"
      ],
      "metadata": {
        "id": "5rZyMbmtAmkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "Hc9yaBd3xhYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **extracting the compessed Dataset**"
      ],
      "metadata": {
        "id": "dhP42SJ1BBDk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "G13DAy5nq_IT",
        "outputId": "75e21a15-e3f9-49f8-e72c-ff35ae585edb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-304aea0147ba>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Dataset.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The dataset is extracted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Dataset.zip'"
          ]
        }
      ],
      "source": [
        "# extracting the compessed Dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/Dataset.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# images without_mask_files\n",
        "with_mask_files = os.listdir('/content/data/with_mask')\n",
        "print(with_mask_files[0:5])\n",
        "print(with_mask_files[-5:])"
      ],
      "metadata": {
        "id": "W7G7XS1-w3Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images without_mask_files\n",
        "without_mask_files=os.listdir('/content/data/without_mask/')\n",
        "print(without_mask_files[0:5])\n",
        "print(without_mask_files[-5:])"
      ],
      "metadata": {
        "id": "Yjj1wTjMBkB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of with mask images:', len(with_mask_files))\n",
        "print('Number of without mask images:', len(without_mask_files))"
      ],
      "metadata": {
        "id": "MjbNe_b2B_oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Labels for the two class of Images**"
      ],
      "metadata": {
        "id": "AG6Qch9MCG7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **in This section we will Creating labels for the two class of images,that meas we will associate each image with here class for Example img_1 have a person that wering a mask then we associate lable 1 and 0 for contraire.**"
      ],
      "metadata": {
        "id": "ck0vsLVTCZM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with_mask_labels=[1]*3725\n",
        "without_mask_labels=[0]*3828\n",
        "\n",
        "print(with_mask_labels[0:10])\n",
        "print(without_mask_labels[0:10])\n",
        "\n",
        "print(len(with_mask_labels))\n",
        "print(len(without_mask_labels))\n"
      ],
      "metadata": {
        "id": "-g1vkgYfCV2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = with_mask_labels + without_mask_labels\n",
        "\n",
        "print(len(labels))\n",
        "print(labels[0:10])\n",
        "print(labels[-10:])"
      ],
      "metadata": {
        "id": "e9gaPVtHD3R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **In this section we will display images**"
      ],
      "metadata": {
        "id": "Wa-jV1pbEPCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img=mpimg.imread('/content/data/with_mask/with_mask_1009.jpg')\n",
        "display_img=plt.imshow(img)"
      ],
      "metadata": {
        "id": "sY7kfRTgEXcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=mpimg.imread('/content/data/without_mask/without_mask_1011.jpg')\n",
        "display_img=plt.imshow(img)"
      ],
      "metadata": {
        "id": "U9jUO9pHE_2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Images Preprocessing**"
      ],
      "metadata": {
        "id": "1DF8Dnu5Fe4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert images to numpy arrays+\n",
        "\n",
        "with_mask_path = '/content/data/with_mask/'\n",
        "\n",
        "data = []\n",
        "\n",
        "for img_file in with_mask_files:\n",
        "\n",
        "  image = Image.open(with_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "\n",
        "\n",
        "without_mask_path = '/content/data/without_mask/'\n",
        "\n",
        "\n",
        "for img_file in without_mask_files:\n",
        "\n",
        "  image = Image.open(without_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)"
      ],
      "metadata": {
        "id": "4PMjMd3GFmMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data))\n",
        "print(len(data))\n",
        "print(data[0])\n",
        "print(type(data[0]))\n",
        "print(data[0].shape)"
      ],
      "metadata": {
        "id": "0CpopjR0Netq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting image list and label list to numpy arrays\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "LqZWcbwBCkym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "uHDdC_hyoX83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "4LMl5efboYBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "ktiMZOYRogVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "X7Gcf-Stogrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data\n",
        "\n",
        "X_train_scaled = X_train/255\n",
        "\n",
        "X_test_scaled = X_test/255"
      ],
      "metadata": {
        "id": "pSfRDlC5ogvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Architecture Of ConvNet/CNN**"
      ],
      "metadata": {
        "id": "RRPkvvj251tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = 2\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "R_wrdn1Polx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the neural network\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "wSedocRool26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the neural network\n",
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"
      ],
      "metadata": {
        "id": "Ay0iLXdYovML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "print('Test Accuracy =', accuracy)\n",
        "model.save('mymodel.h5',model)"
      ],
      "metadata": {
        "id": "TjbvjFPQovPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = history\n",
        "\n",
        "# plot the loss value\n",
        "plt.plot(h.history['loss'], label='train loss')\n",
        "plt.plot(h.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy value\n",
        "plt.plot(h.history['acc'], label='train accuracy')\n",
        "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kldyhKOio2yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction)\n",
        "\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "\n",
        "if input_pred_label == 1:\n",
        "\n",
        "  print('The person in the image is wearing a mask')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('The person in the image is not wearing a mask')"
      ],
      "metadata": {
        "id": "faS0gZlto21d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}